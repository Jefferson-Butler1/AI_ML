{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jefferson-Butler1/AI_ML/blob/main/Butler_CNN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01496206",
      "metadata": {
        "id": "01496206"
      },
      "source": [
        "# CS369 Image Classifier\n",
        "## Starter Code\n",
        "\n",
        "This notebook is intended to be a starting point for writing your image classifier.\n",
        "\n",
        "Start by setting the `root_path` variable to point to the dataset on your computer (a relative path is ok). You can verify that you're loading the data correctly by printing out the list of label names.\n",
        "\n",
        "As is, this code loads each image and converts the image into a 1D luminance histogram. This is a very simple feature vector, and you are encouraged to experiment with more complicated ones to improve the accuracy of your predictions.\n",
        "\n",
        "The labels, filenames, and histogram feature vectors are stored in a pandas data frame in case you want to save and load them instead of re-computing them each time.\n",
        "\n",
        "The last part of the code trains a simple SVM classifier and computes the accuracy of the trained model on the same data it was just trained on. You're encouraged to segment the data into Train and Validation subsets, which will allow you to verify that your model isn't over-fitting to the training data.\n",
        "\n",
        "You will need to add several components to the code, listed below. We will talk about these in class, and you can also look up the documentation for the suggested functions online.\n",
        "\n",
        "A rubric describing how the project will be graded will be provided separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "db18b596",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting prompt-toolkit\n",
            "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting wcwidth (from prompt-toolkit)\n",
            "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
            "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, prompt-toolkit\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.13\n",
            "    Uninstalling wcwidth-0.2.13:\n",
            "      Successfully uninstalled wcwidth-0.2.13\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.43\n",
            "    Uninstalling prompt-toolkit-3.0.43:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.43\n",
            "Successfully installed prompt-toolkit-3.0.43 wcwidth-0.2.13\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.11/site-packages (1.0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/site-packages (from jupyter) (7.0.7)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.11/site-packages (from jupyter) (5.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/site-packages (from jupyter) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/site-packages (from jupyter) (7.14.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/site-packages (from jupyter) (6.29.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/site-packages (from jupyter) (8.1.1)\n",
            "Requirement already satisfied: appnope in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.3)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (0.2.1)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (8.20.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (8.6.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (5.7.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (5.9.8)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (25.1.2)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (6.4)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.11/site-packages (from ipykernel->jupyter) (5.14.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.11/site-packages (from ipywidgets->jupyter) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.11/site-packages (from ipywidgets->jupyter) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.11/site-packages (from jupyter-console->jupyter) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/site-packages (from jupyter-console->jupyter) (2.17.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (3.1.3)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (2.1.5)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (0.9.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.11/site-packages (from nbconvert->jupyter) (1.2.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/site-packages (from notebook->jupyter) (2.12.5)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /usr/local/lib/python3.11/site-packages (from notebook->jupyter) (2.25.2)\n",
            "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /usr/local/lib/python3.11/site-packages (from notebook->jupyter) (4.0.11)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.11/site-packages (from notebook->jupyter) (0.2.3)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.11/site-packages (from qtconsole->jupyter) (2.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.1.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (4.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.9.0)\n",
            "Requirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.5.2)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.6.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.19.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.18.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.7.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter) (2.0.4)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter) (2.2.2)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.14.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.9.14)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (4.21.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.31.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.19.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (22.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.17.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2024.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.4)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.8.19.20240106)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install prompt-toolkit -U --force-reinstall\n",
        "! pip install jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f9a206bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
            "Collecting pillow\n",
            "  Using cached pillow-10.2.0-cp311-cp311-macosx_10_10_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.4.1.post1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Using cached scipy-1.12.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow)\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
            "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting h5py>=2.9.0 (from tensorflow)\n",
            "  Using cached h5py-3.10.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Using cached libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow)\n",
            "  Using cached ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting packaging (from tensorflow)\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow)\n",
            "  Using cached setuptools-69.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
            "  Using cached wrapt-1.14.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Using cached grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached google_auth-2.28.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
            "Using cached pandas-2.2.0-cp311-cp311-macosx_10_9_x86_64.whl (12.5 MB)\n",
            "Using cached pillow-10.2.0-cp311-cp311-macosx_10_10_x86_64.whl (3.5 MB)\n",
            "Using cached scikit_learn-1.4.1.post1-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n",
            "Using cached tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl (239.1 MB)\n",
            "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
            "Using cached grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
            "Using cached h5py-3.10.0-cp311-cp311-macosx_10_9_x86_64.whl (3.2 MB)\n",
            "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Using cached libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\n",
            "Using cached ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\n",
            "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
            "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Using cached scipy-1.12.0-cp311-cp311-macosx_10_9_x86_64.whl (38.9 MB)\n",
            "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "Using cached setuptools-69.1.0-py3-none-any.whl (819 kB)\n",
            "Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_10_14_x86_64.whl (2.5 MB)\n",
            "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
            "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Using cached wrapt-1.14.1-cp311-cp311-macosx_10_9_x86_64.whl (35 kB)\n",
            "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Using cached google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
            "Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
            "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
            "Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
            "Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
            "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl (121 kB)\n",
            "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl (14 kB)\n",
            "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "Installing collected packages: pytz, libclang, flatbuffers, wrapt, wheel, urllib3, tzdata, typing-extensions, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, pillow, packaging, oauthlib, numpy, MarkupSafe, markdown, keras, joblib, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, scipy, rsa, requests, python-dateutil, pyasn1-modules, opt-einsum, ml-dtypes, h5py, google-pasta, astunparse, scikit-learn, requests-oauthlib, pandas, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.1\n",
            "    Uninstalling pytz-2024.1:\n",
            "      Successfully uninstalled pytz-2024.1\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 16.0.6\n",
            "    Uninstalling libclang-16.0.6:\n",
            "      Successfully uninstalled libclang-16.0.6\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.42.0\n",
            "    Uninstalling wheel-0.42.0:\n",
            "      Successfully uninstalled wheel-0.42.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.1\n",
            "    Uninstalling urllib3-2.2.1:\n",
            "      Successfully uninstalled urllib3-2.2.1\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2024.1\n",
            "    Uninstalling tzdata-2024.1:\n",
            "      Successfully uninstalled tzdata-2024.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.3.0\n",
            "    Uninstalling threadpoolctl-3.3.0:\n",
            "      Successfully uninstalled threadpoolctl-3.3.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.4.0\n",
            "    Uninstalling termcolor-2.4.0:\n",
            "      Successfully uninstalled termcolor-2.4.0\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.36.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.36.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.36.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 69.1.0\n",
            "    Uninstalling setuptools-69.1.0:\n",
            "      Successfully uninstalled setuptools-69.1.0\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.5.1\n",
            "    Uninstalling pyasn1-0.5.1:\n",
            "      Successfully uninstalled pyasn1-0.5.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 10.2.0\n",
            "    Uninstalling pillow-10.2.0:\n",
            "      Successfully uninstalled pillow-10.2.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.5.2\n",
            "    Uninstalling Markdown-3.5.2:\n",
            "      Successfully uninstalled Markdown-3.5.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.62.0\n",
            "    Uninstalling grpcio-1.62.0:\n",
            "      Successfully uninstalled grpcio-1.62.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.2\n",
            "    Uninstalling cachetools-5.3.2:\n",
            "      Successfully uninstalled cachetools-5.3.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.1.0\n",
            "    Uninstalling absl-py-2.1.0:\n",
            "      Successfully uninstalled absl-py-2.1.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.1\n",
            "    Uninstalling Werkzeug-3.0.1:\n",
            "      Successfully uninstalled Werkzeug-3.0.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.12.0\n",
            "    Uninstalling scipy-1.12.0:\n",
            "      Successfully uninstalled scipy-1.12.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1-modules 0.3.0\n",
            "    Uninstalling pyasn1-modules-0.3.0:\n",
            "      Successfully uninstalled pyasn1-modules-0.3.0\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt-einsum 3.3.0\n",
            "    Uninstalling opt-einsum-3.3.0:\n",
            "      Successfully uninstalled opt-einsum-3.3.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.10.0\n",
            "    Uninstalling h5py-3.10.0:\n",
            "      Successfully uninstalled h5py-3.10.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.4.1.post1\n",
            "    Uninstalling scikit-learn-1.4.1.post1:\n",
            "      Successfully uninstalled scikit-learn-1.4.1.post1\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 1.3.1\n",
            "    Uninstalling requests-oauthlib-1.3.1:\n",
            "      Successfully uninstalled requests-oauthlib-1.3.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.0\n",
            "    Uninstalling pandas-2.2.0:\n",
            "      Successfully uninstalled pandas-2.2.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.28.1\n",
            "    Uninstalling google-auth-2.28.1:\n",
            "      Successfully uninstalled google-auth-2.28.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 certifi-2024.2.2 charset-normalizer-3.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.28.1 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.62.0 h5py-3.10.0 idna-3.6 joblib-1.3.2 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.2 pandas-2.2.0 pillow-10.2.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 python-dateutil-2.8.2 pytz-2024.1 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.4.1.post1 scipy-1.12.0 setuptools-69.1.0 six-1.16.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 threadpoolctl-3.3.0 typing-extensions-4.9.0 tzdata-2024.1 urllib3-2.2.1 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy pandas pillow scikit-learn tensorflow --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b32a7ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/x2/2c9mhbn90rq25wcmzwtdlyww0000gn/T/ipykernel_48426/1307912617.py:4: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"it's tensorFlow\")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kIek4tRPRneN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIek4tRPRneN",
        "outputId": "91ba62e1-69eb-4885-b7ae-de73a82ffe5c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f_WvFdZSUiaE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_WvFdZSUiaE",
        "outputId": "e5929db8-d103-4f64-b70f-7a53eeb0a114"
      },
      "outputs": [],
      "source": [
        "###unzip data\n",
        "# Path to the zipped folder in your Google Drive\n",
        "zip_path = '/content/drive/MyDrive/CS 369 Shared Folder/Project Resources/Intel Training Dataset.zip'\n",
        "\n",
        "# Destination folder where the zip file will be extracted\n",
        "extracted_path = './Intel\\ Training\\ Dataset/'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(extracted_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "print(\"Extraction complete. Data is ready for use.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef542d3",
      "metadata": {
        "id": "2ef542d3"
      },
      "outputs": [],
      "source": [
        "# Path to Dataset\n",
        "root_path = './Intel\\ Training\\ Dataset/Intel Training Dataset/'\n",
        "\n",
        "# split into subfolders based on class label\n",
        "subfolders = sorted(glob(root_path + '*'))\n",
        "label_names = [p.split('/')[-1] for p in subfolders]\n",
        "# print(label_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900a15e0",
      "metadata": {
        "id": "900a15e0"
      },
      "outputs": [],
      "source": [
        "# create a list to organize labels, filenames, and images\n",
        "data = []\n",
        "image_height = 150\n",
        "image_width = 150\n",
        "channels = 3  # Assuming RGB images\n",
        "\n",
        "for i, (label, subfolder) in enumerate(zip(label_names, subfolders)):\n",
        "    # get list of file paths for each subfolder\n",
        "    file_paths = sorted(glob(subfolder + '/*.jpg'))\n",
        "    for f in file_paths:\n",
        "        # read image and resize if necessary (adjust dimensions as needed)\n",
        "        img = Image.open(f).resize((image_height, image_width))\n",
        "        fname = f.split('/')[-1].split('_')[-1]\n",
        "\n",
        "        # append to data list with labels\n",
        "        data.append({'labelname': label,\n",
        "                     'filename': fname,\n",
        "                     'labelnum': i,\n",
        "                     'image': np.array(img)})\n",
        "\n",
        "# convert to dataframe for storage\n",
        "# can also export to a file here\n",
        "df = pd.DataFrame(data=data)\n",
        "\n",
        "# Determine the number of classes\n",
        "num_classes = len(df['labelnum'].unique())\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['labelnum'], random_state=42)\n",
        "\n",
        "# Separate features (images) and labels\n",
        "X_train = np.array(train_df['image'].tolist())\n",
        "y_train = np.array(train_df['labelnum'])\n",
        "\n",
        "X_test = np.array(test_df['image'].tolist())\n",
        "y_test = np.array(test_df['labelnum'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t_tVLXHNHOOk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_tVLXHNHOOk",
        "outputId": "7b3b2e71-0371-42b3-e39e-599fadc57389"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, channels)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Add dropout for regularization\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy on Test Data with CNN: {:.2f}%'.format(test_accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oZTmT_viHPKx",
      "metadata": {
        "id": "oZTmT_viHPKx"
      },
      "source": [
        "THis is where it ends\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a3eaaf",
      "metadata": {
        "id": "c1a3eaaf"
      },
      "outputs": [],
      "source": [
        "# re-load data\n",
        "label_array = df['labelnum'] # vector\n",
        "feature_matrix = np.vstack(df['features']) #2D for lumhist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p2Ap77Grg-W3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2Ap77Grg-W3",
        "outputId": "42817196-58db-4fe3-e8e7-e867533ad885"
      },
      "outputs": [],
      "source": [
        "# Split the combined features into train and test sets\n",
        "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n",
        "    feature_matrix,\n",
        "    label_array,\n",
        "    test_size=0.2,\n",
        "    stratify=label_array,\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_combined_scaled = scaler.fit_transform(X_train_combined)\n",
        "X_test_combined_scaled = scaler.transform(X_test_combined)\n",
        "\n",
        "# Train a Gradient Boosting classifier\n",
        "gb_clf_combined = GradientBoostingClassifier(n_estimators=1000,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    max_features='sqrt',\n",
        "    random_state=0,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=10,\n",
        "    tol=0.001,)\n",
        "gb_clf_combined.fit(X_train_combined_scaled, y_train_combined)\n",
        "\n",
        "# #Train a Random Forest model\n",
        "# rf_clf_combined = RandomForestClassifier(n_estimators = 50,\n",
        "#                                   max_depth = 7,\n",
        "#                                   min_samples_split = 6,\n",
        "#                                   min_samples_leaf = 8,\n",
        "#                                   max_features = 'sqrt',\n",
        "#                                   bootstrap = False)\n",
        "# rf_clf_combined.fit(X_train_combined_scaled, y_train_combined)\n",
        "\n",
        "# Report accuracy on the test data\n",
        "\n",
        "# test_predictions_combined_rf = rf_clf_combined.score(X_test_combined_scaled, y_test_combined)\n",
        "# print('Accuracy on Test Data with Combined Features & Random Forest: {:.2f}%'.format(test_predictions_combined_rf * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FR1cHRHAAGVV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR1cHRHAAGVV",
        "outputId": "365d54a4-08b5-4190-f793-ebc951371a85"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_predictions_combined_gb = gb_clf_combined.score(X_train_combined_scaled, y_train_combined)\n",
        "print('Accuracy on Train Data with Combined Features & Gradient Boosting: {:.2f}%'.format(test_predictions_combined_gb * 100))\n",
        "\n",
        "test_predictions_combined_gb = gb_clf_combined.score(X_test_combined_scaled, y_test_combined)\n",
        "print('Accuracy on Test Data with Combined Features & Gradient Boosting: {:.2f}%'.format(test_predictions_combined_gb * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v5j2w2lVjwpw",
      "metadata": {
        "id": "v5j2w2lVjwpw"
      },
      "outputs": [],
      "source": [
        "# Train a Neural Network classifier\n",
        "nn_clf_combined = MLPClassifier(hidden_layer_sizes=(100,50),\n",
        "                                activation='relu',\n",
        "                                solver='adam',\n",
        "                                alpha=0.01,\n",
        "                                max_iter=500,\n",
        "                                random_state=42)\n",
        "nn_clf_combined.fit(X_train_combined_scaled, y_train_combined)\n",
        "\n",
        "# Report accuracy on the test data\n",
        "test_predictions_combined_nn = nn_clf_combined.score(X_train_combined_scaled, y_train_combined)\n",
        "print('Accuracy on Train Data with Combined Features & Neural Network: {:.2f}%'.format(test_predictions_combined_nn * 100))\n",
        "test_predictions_combined_nn = nn_clf_combined.score(X_test_combined_scaled, y_test_combined)\n",
        "print('Accuracy on Test Data with Combined Features & Neural Network: {:.2f}%'.format(test_predictions_combined_nn * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pOnh5TMZtN7m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOnh5TMZtN7m",
        "outputId": "ad59bdd7-7def-4ba6-b981-806d63ae2c62"
      },
      "outputs": [],
      "source": [
        "# Report accuracy on the test data\n",
        "test_predictions_combined_nn = nn_clf_combined.score(X_train_combined_scaled, y_train_combined)\n",
        "print('Accuracy on Train Data with Combined Features & Neural Network: {:.2f}%'.format(test_predictions_combined_nn * 100))\n",
        "test_predictions_combined_nn = nn_clf_combined.score(X_test_combined_scaled, y_test_combined)\n",
        "print('Accuracy on Test Data with Combined Features & Neural Network: {:.2f}%'.format(test_predictions_combined_nn * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KxRlJ2L-XKTL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxRlJ2L-XKTL",
        "outputId": "c4b62281-688e-4c7a-c6d6-4bcd66ffdcff"
      },
      "outputs": [],
      "source": [
        "# Split lumhist into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix_lum, label_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Report accuracy on the test data\n",
        "test_predictions = rf_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, test_predictions)\n",
        "print('Accuracy on Test Data: {:.2f}%'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wRnVvWbpRcMZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRnVvWbpRcMZ",
        "outputId": "000d4dc7-8a2d-4f38-99e4-b911ffbe598d"
      },
      "outputs": [],
      "source": [
        "# Split hog into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix_hog, label_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Report accuracy on the test data\n",
        "test_predictions = rf_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, test_predictions)\n",
        "print('Accuracy on Test Data: {:.2f}%'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcxiJ-v3YVMR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcxiJ-v3YVMR",
        "outputId": "b1845592-6bc9-40fe-bb09-08f39e4888a9"
      },
      "outputs": [],
      "source": [
        "# Split hog into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix_hog, label_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Gradient Boosting classifier\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Report accuracy on the test data\n",
        "test_predictions_gb = gb_clf.predict(X_test)\n",
        "accuracy_gb = accuracy_score(y_test, test_predictions_gb)\n",
        "print('Accuracy on Test Data with Gradient Boosting: {:.2f}%'.format(accuracy_gb * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "543f7127",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "543f7127",
        "outputId": "977a2330-2254-405c-e558-978ba8c2553f"
      },
      "outputs": [],
      "source": [
        "### from starter code\n",
        "# train a simple classifier\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(feature_matrix_lum, label_array)\n",
        "\n",
        "# report overall accuracy on the training data\n",
        "print('Total Accuracy: {}'.format(clf.score(feature_matrix_lum, label_array)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde5aef1",
      "metadata": {
        "id": "bde5aef1"
      },
      "outputs": [],
      "source": [
        "# Project To Do's\n",
        "# 0. split the data into Train and Validation sets\n",
        "# 1. use sklearn.metrics.confusion_matrix to get more detailed results\n",
        "# 2. use sklearn.model_selection.GridSearchCV to try different params\n",
        "# 3. try different feature vectors and classifiers to improve accuracy\n",
        "# 4. use python's time.time() function to measure compute time costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-fcTJNq6aCq5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "-fcTJNq6aCq5",
        "outputId": "3459c93e-3e2b-4555-8eae-ed9007de3412"
      },
      "outputs": [],
      "source": [
        "### confusion matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix_gb = confusion_matrix(y_test, test_predictions_gb)\n",
        "\n",
        "# Visualize confusion matrix as heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix_gb, annot=True, cmap='Blues', fmt='d', xticklabels=label_names, yticklabels=label_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Gradient Boosting Classifier')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
